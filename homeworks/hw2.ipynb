{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hoeffding Inequality\n",
    "\n",
    "Run a computer simulation for flipping 1,000 virtual fair coins. Flip each coin independently 10 times.\n",
    "\n",
    "Note: this is a first naive implementation, below is a much faster one using binomial distribution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment():\n",
    "    coins_flips = []\n",
    "\n",
    "    # 0 is tail\n",
    "    # 1 is head\n",
    "    \n",
    "    # For 1000 coins\n",
    "    for _ in range(1000):\n",
    "        coin_flips = []\n",
    "        \n",
    "        # Flip the coin 10 times\n",
    "        for _ in range(10):\n",
    "            coin_flips.append(random.choice([0,1]))\n",
    "        \n",
    "        coins_flips.append(coin_flips)\n",
    "\n",
    "    # c1 is the first coin flipped\n",
    "    c_1 = coins_flips[0]\n",
    "    ν1 = sum(c_1)/10\n",
    "\n",
    "    # crand is a coin chosen randomly from the 1,000\n",
    "    c_rand = random.choice(coins_flips)\n",
    "    νrand = sum(c_rand)/10\n",
    "\n",
    "    # cmin is the coin which had the minimum frequency of heads\n",
    "    coins_heads_frequency = list(map(lambda x: sum(x), coins_flips))\n",
    "    min_heads_frequency = min(coins_heads_frequency)\n",
    "    a = np.array(coins_heads_frequency)\n",
    "    index = np.where(a == min_heads_frequency)[0][0]\n",
    "    c_min = coins_flips[index]\n",
    "    νmin = sum(c_min)/10\n",
    "    \n",
    "    return (ν1, νrand, νmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00503\n"
     ]
    }
   ],
   "source": [
    "experiments = []\n",
    "\n",
    "# Run the experiment 100,000 times in order to get a full distribution of ν1, νrand, and νmin\n",
    "NUMBER_OF_RUNS = 100000\n",
    "\n",
    "for _ in range(NUMBER_OF_RUNS):\n",
    "    experiments.append(run_experiment())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'experiments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-186-eb6a4a7dcd46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mavg_νmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mNUMBER_OF_RUNS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Average νmin is {avg_νmin}, therefore closest to 0.01: Answer [B]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'experiments' is not defined"
     ]
    }
   ],
   "source": [
    "avg_νmin = sum(list(map(lambda x: x[2], experiments)))/NUMBER_OF_RUNS\n",
    "print(f'Average νmin is {avg_νmin}, therefore closest to 0.01: Answer [B]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1-bis Hoeffding Inequality with binomial distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average νmin is 0.03736299999999999, therefore closest to 0.01: Answer [B])\n"
     ]
    }
   ],
   "source": [
    "import scipy.special\n",
    "\n",
    "N = 100000\n",
    "v_first = np.zeros(N)\n",
    "v_min = np.zeros(N)\n",
    "v_rand = np.zeros(N)\n",
    "\n",
    "#Loop starts\n",
    "for i in range(N):\n",
    "    n,p = 10, 0.5\n",
    "    flips = np.random.binomial(n, p, 1000)\n",
    "\n",
    "    # Indices\n",
    "    first_coin = 0\n",
    "    min_coin = np.argmin(flips)\n",
    "    rand_coin = np.random.randint(0,1000)\n",
    "\n",
    "    v_first[i] = flips[first_coin]/n\n",
    "    v_min[i] = flips[min_coin]/n\n",
    "    v_rand[i] = flips[rand_coin]/n\n",
    "\n",
    "#Loop ends\n",
    "\n",
    "print(f'Average νmin is {np.average(v_min)}, therefore closest to 0.01: Answer [B])')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 4 7 6 4 2 6 6 4 4]\n"
     ]
    }
   ],
   "source": [
    "# Sandbox\n",
    "n,p = 10, 0.5\n",
    "flips = np.random.binomial(n, p, 10)\n",
    "print(flips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Which coin(s) has a distribution of ν that satisfies the (single-bin) Hoeffding Inequality?\n",
    "\n",
    "> The main point is that once you consider the sample, the probability becomes conditional on how this sample came out, and that could violate the 2e^{-2\\epsilon^2N} bound, whereas the probability before a sample was drawn always obeys the bound.\n",
    "\n",
    "Therefore only c1 and c_rand satisfy: Answer [D]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from hw1 import is_misclassified_point, create_dataset, create_experiment\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustration of Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, dataset = create_experiment(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39802354 0.2636148  1.24667411]\n"
     ]
    }
   ],
   "source": [
    "# We can find w either using the Pseudo-Inverse\n",
    "def pseudo_inverse(dataset):\n",
    "    X = np.array(list(map(lambda x: [1] + x[0], dataset)))\n",
    "\n",
    "    y = np.array(list(map(lambda x: x[1], dataset)))\n",
    "\n",
    "    # Using pseudo-inverse\n",
    "    pseudo_inverse = np.dot(np.linalg.inv(np.dot(X.transpose(), X)), X.transpose())\n",
    "\n",
    "    w = np.dot(pseudo_inverse, y)\n",
    "    \n",
    "    return w\n",
    "\n",
    "w = pseudo_inverse(dataset)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39802354 0.2636148  1.24667411]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46864097866442167"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or we can use Scikit Linear Regression\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = np.array(list(map(lambda x: [1] + x[0], dataset)))\n",
    "\n",
    "y = np.array(list(map(lambda x: x[1], dataset)))\n",
    "\n",
    "reg = LinearRegression().fit(X, y)\n",
    "\n",
    "sci_w = reg.coef_\n",
    "sci_w[0] = reg.intercept_\n",
    "print(sci_w)\n",
    "\n",
    "reg.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "[2.39802354 1.09799609 5.84751276]\n"
     ]
    }
   ],
   "source": [
    "# Apply PLA on Linear Regression weights, using them as initial vector\n",
    "pla_w = w\n",
    "\n",
    "misclassified_points = list(filter(lambda x: is_misclassified_point(pla_w, x), dataset))\n",
    "\n",
    "i = 0\n",
    "while len(misclassified_points) > 0:\n",
    "    # Pick a random misclassified point\n",
    "    data = random.sample(misclassified_points, 1)[0]\n",
    "\n",
    "    # Apply PLA iteration\n",
    "    pla_w = pla_w + np.dot(data[1], [1, data[0][0], data[0][1]])\n",
    "\n",
    "    misclassified_points = list(filter(lambda x: is_misclassified_point(pla_w, x), dataset))\n",
    "    i += 1\n",
    "    \n",
    "print(i)\n",
    "print(pla_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.axis([-1, 1, -1, 1])\n",
    "\n",
    "x = np.linspace(-1, 1, 2)\n",
    "plt.plot(x, f(x), color='blue')\n",
    "\n",
    "def g(x):\n",
    "    y = -(w[1]*x+w[0])/w[2]\n",
    "    return y\n",
    "\n",
    "plt.plot(x, g(x), color='yellow')\n",
    "\n",
    "def pla_g(x):\n",
    "    y = -(pla_w[1]*x+pla_w[0])/pla_w[2]\n",
    "    return y\n",
    "\n",
    "plt.plot(x, pla_g(x), color='orange')\n",
    "\n",
    "for data in dataset:\n",
    "    point = data[0]\n",
    "    output = data[1]\n",
    "    plt.plot(point[0], point[1],  'go' if output > 0 else 'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = []\n",
    "\n",
    "N = 100\n",
    "\n",
    "#  Repeat the experiment 1000 times and take the average\n",
    "for _ in range(1000):\n",
    "    f, dataset = create_experiment(N)\n",
    "    \n",
    "    # Use Linear Regression to find g\n",
    "    w = pseudo_inverse(dataset)\n",
    "    \n",
    "    # evaluate Ein, the fraction of in-sample points which got classified incorrectly\n",
    "    misclassified_points = list(filter(lambda data: is_misclassified_point(w, data), dataset))\n",
    "    Ein = len(misclassified_points)/N\n",
    "    \n",
    "    experiments.append([w, Ein, f, dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Ein is 0.03314, there closed to 0.01: Answer C\n"
     ]
    }
   ],
   "source": [
    "avg_Ein = np.average(list(map(lambda x: x[1], experiments)))\n",
    "print(f'Average Ein is {avg_Ein}, there closed to 0.01: Answer C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eouts = []\n",
    "\n",
    "#  Repeat the experiment 1000 times and take the average\n",
    "for i in range(1000):\n",
    "    # Take the g from Problem 5\n",
    "    experiment = experiments[i]\n",
    "    w = experiment[0]\n",
    "    \n",
    "    f = experiment[2]\n",
    "    \n",
    "    # generate 1000 fresh points and use them to estimate the out-of-sample error Eout of g that you got in Problem 5\n",
    "    SEPARATED_DATASET_SIZE = 1000\n",
    "    separated_dataset = create_dataset(f, SEPARATED_DATASET_SIZE)\n",
    "    \n",
    "    misclassified_points = list(filter(lambda x: is_misclassified_point(w, x), separated_dataset))\n",
    "\n",
    "    error_rate = len(misclassified_points)/SEPARATED_DATASET_SIZE\n",
    "    \n",
    "    Eouts.append(error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Eout is 0.04286800000000001, there closest to 0.01: Answer C\n"
     ]
    }
   ],
   "source": [
    "avg_Eout = np.average(Eouts)\n",
    "print(f'Average Eout is {avg_Eout}, there closest to 0.01: Answer C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "\n",
    "iterations = []\n",
    "\n",
    "#  Repeat the experiment 1000 times and take the average\n",
    "for _ in range(1000):\n",
    "    f, dataset = create_experiment(N)\n",
    "    \n",
    "    # Find weights using Linear Regression \n",
    "    # use them as a vector of initial weights for the Perceptron Learning Algorithm\n",
    "    w = pseudo_inverse(dataset)\n",
    "    \n",
    "    misclassified_points = list(filter(lambda x: is_misclassified_point(w, x), dataset))\n",
    "    \n",
    "    i = 0\n",
    "    while len(misclassified_points) > 0:\n",
    "        # Pick a random misclassified point\n",
    "        data = random.sample(misclassified_points, 1)[0]\n",
    "\n",
    "        # Apply PLA iteration\n",
    "        w = w + np.dot(data[1], [1, data[0][0], data[0][1]])\n",
    "\n",
    "        misclassified_points = list(filter(lambda data: is_misclassified_point(w, data), dataset))\n",
    "        i += 1\n",
    "        \n",
    "    iterations.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of iterations is 3.739, there closest to 1: Answer A\n"
     ]
    }
   ],
   "source": [
    "avg_iterations = np.average(iterations)\n",
    "print(f'Average number of iterations is {avg_iterations}, there closest to 1: Answer A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonlinear Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a training set of N = 1000 points on X = [−1, 1] × [−1, 1] with a uniform probability of picking each x ∈ X\n",
    "import math\n",
    "\n",
    "# Consider the target function:\n",
    "def f(x):\n",
    "    y = np.sign(x[0]**2 + x[1]**2 - 0.6)\n",
    "    return y\n",
    "\n",
    "def create_dataset_with_noise(N, ratio):\n",
    "    dataset = [];\n",
    "    \n",
    "    for _ in range(N):\n",
    "        # Choose the inputs xn of the data set as random points\n",
    "        x1, x2 = np.random.uniform(-1,1,2)\n",
    "        \n",
    "        \n",
    "        y = f([x1,x2])\n",
    "\n",
    "        dataset.append([[x1,x2], y])\n",
    "        \n",
    "    # Generate simulated noise \n",
    "    # by flipping the sign of the output in a randomly selected 10% subset of the generated training set.\n",
    "    indices = random.sample(range(N), int(float(N)*ratio))\n",
    "\n",
    "    for i in indices:\n",
    "        dataset[i][1] = dataset[i][1] * (-1)\n",
    "    \n",
    "    return dataset;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eins = []\n",
    "\n",
    "N = 1000\n",
    "ratio = 0.1\n",
    "\n",
    "for _ in range(1000):\n",
    "    dataset = create_dataset_with_noise(N, 0.1)\n",
    "    \n",
    "    # Use Linear Regression to find g\n",
    "    w = pseudo_inverse(dataset)\n",
    "    \n",
    "    # evaluate Ein, the fraction of in-sample points which got classified incorrectly\n",
    "    misclassified_points = list(filter(lambda x: is_misclassified_point(w, x), dataset))\n",
    "    Ein = len(misclassified_points)/N\n",
    "    \n",
    "    Eins.append(Ein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Ein is 0.501289, there closest to 0.5: Answer [D]\n"
     ]
    }
   ],
   "source": [
    "avg_Ein = np.average(Eins)\n",
    "print(f'Average Ein is {avg_Ein}, there closest to 0.5: Answer [D]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fi(x):\n",
    "    y = [1] + x + [x[0] * x[1]] + [x[0]**2] + [x[1]**2]\n",
    "    return y\n",
    "\n",
    "N = 1000\n",
    "noise = 0.1\n",
    "dataset = create_dataset_with_noise(N, noise)\n",
    "\n",
    "#  transform the training data into the nonlinear feature vector, using Fi\n",
    "X = np.array(list(map(lambda x: fi(x[0]), dataset)))\n",
    "\n",
    "# y vector of labels does not change\n",
    "y = np.array(list(map(lambda x: x[1], dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_inverse = np.dot(np.linalg.inv(np.dot(X.transpose(), X)), X.transpose())\n",
    "\n",
    "w_tild = np.dot(pseudo_inverse, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_a = [-1, -0.05, 0.08, 0.13, 1.5, 1.5]\n",
    "w_b = [-1, -0.05, 0.08, 0.13, 1.5, 15]\n",
    "w_c = [-1, -0.05, 0.08, 0.13, 15, 1.5]\n",
    "w_d = [-1, -1.5, 0.08, 0.13, 0.05, 0.05]\n",
    "w_e = [-1, -0.05, 0.08, 1.5, 0.15, 0.15]\n",
    "\n",
    "hypothesis = [w_a, w_b, w_c, w_d, w_e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([96., 70., 62., 57., 54.])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We test other 100 random points which hypothesis agrees the most with our hypothesis\n",
    "indices = random.sample(range(N), int(float(N)*ratio))\n",
    "\n",
    "agreements = np.zeros(5)\n",
    "\n",
    "for i in indices:\n",
    "    data = dataset[i]\n",
    "    \n",
    "    x = data[0]\n",
    "\n",
    "    for j in range(len(hypothesis)):\n",
    "        if np.sign(np.dot(hypothesis[j], fi(x))) == np.sign(np.dot(w_tild, fi(x))):\n",
    "            agreements[j] += 1\n",
    "    \n",
    "agreements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first hypothesis is the closest: Answer [A]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "> What is the closest value to the classification out-of-sample error Eout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eouts = []\n",
    "\n",
    "# Adapt missclassification to Fi transformation\n",
    "def is_missclassified(w, data):\n",
    "    return np.sign(np.dot(w, fi(data[0]))) != data[1]\n",
    "\n",
    "SEPARATED_DATASET_SIZE = 1000\n",
    "\n",
    "# Create 1000 times, 1000 new fresh points to get the average error out-of-sample Eout\n",
    "for _ in range(1000):\n",
    "    separated_dataset = create_dataset_with_noise(SEPARATED_DATASET_SIZE, noise)\n",
    "\n",
    "    misclassified_points = list(filter(lambda x: is_missclassified(w_tild, x), separated_dataset))\n",
    "\n",
    "    error_rate = len(misclassified_points)/SEPARATED_DATASET_SIZE\n",
    "    Eouts.append(error_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Eout is 0.12868700000000002, there closest to 0.1: Answer [B]\n"
     ]
    }
   ],
   "source": [
    "avg_Eout = np.average(Eouts)\n",
    "print(f'Average Eout is {avg_Eout}, there closest to 0.1: Answer [B]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
